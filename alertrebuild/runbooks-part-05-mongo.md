# Part 5: DB-MONGO â€” MongoDB/DocumentDB Runbooks

> **Part:** 5 of 10 | **Version:** 1.0 | **Date:** 2026-02-16 | **Status:** Complete
>
> Bilingual runbooks (English + ä¸­æ–‡) for all 5 MongoDB/DocumentDB alerts.
> Format: Merged 5A Response Pattern + 12-Section SOP structure.

---

## Table of Contents / ç›®å½•

| # | Alert ID | Alert Name | Severity | Tier | Page |
|---|----------|-----------|----------|------|------|
| 1 | LCK-MG-001 | MongoCpuHigh_Warning | warning | 2 | [Link](#lck-mg-001--mongocpuhigh_warning) |
| 2 | LCK-MG-002 | MongoCpuHigh_Critical | critical | 3 | [Link](#lck-mg-002--mongocpuhigh_critical) |
| 3 | LCK-MG-003 | MongoMemoryLow_Warning | warning | 2 | [Link](#lck-mg-003--mongomemorylow_warning) |
| 4 | LCK-MG-004 | MongoMemoryLow_Critical | critical | 3 | [Link](#lck-mg-004--mongomemorylow_critical) |
| 5 | LCK-MG-005 | MongoConnectionHigh_Warning | warning | 2 | [Link](#lck-mg-005--mongoconnectionhigh_warning) |

---

## Category Overview / åˆ†ç±»æ¦‚è¿°

**MongoDB/DocumentDB** alerts monitor the 4 DocumentDB (MongoDB-compatible) instances in AWS `us-east-1`.
DocumentDB uses an Aurora-based storage engine with MongoDB API compatibility.

**MongoDB/DocumentDB** å‘Šè­¦ç›‘æ§ AWS `us-east-1` ä¸­çš„ 4 ä¸ª DocumentDBï¼ˆå…¼å®¹ MongoDBï¼‰å®ä¾‹ã€‚
DocumentDB ä½¿ç”¨åŸºäº Aurora çš„å­˜å‚¨å¼•æ“ï¼Œå…¼å®¹ MongoDB APIã€‚

| Feature / ç‰¹æ€§ | AWS DocumentDB | Self-managed MongoDB |
|----------------|---------------|---------------------|
| Storage engine / å­˜å‚¨å¼•æ“ | Aurora-based (auto-grows) | WiredTiger |
| Max connections / æœ€å¤§è¿æ¥æ•° | ~100 per GiB RAM | Configurable |
| Backup / å¤‡ä»½ | Automatic continuous | Manual/oplog |
| Scaling / æ‰©å±• | Instance class change | Shard/replica set |
| Monitoring / ç›‘æ§ | CloudWatch + Prometheus exporter | mongostat/mongotop |

### Prometheus Datasource / Prometheus æ•°æ®æº

| Datasource | UID | Used For / ç”¨é€” |
|------------|-----|----------|
| UMBQuerier-Luckin | `df8o21agxtkw0d` | MongoDB CPU, memory, connection metrics |
| prometheus | `ff7hkeec6c9a8e` | General infrastructure metrics / é€šç”¨åŸºç¡€è®¾æ–½æŒ‡æ ‡ |

### Key Endpoints / å…³é”®ç«¯ç‚¹

| Resource / èµ„æº | Value / å€¼ |
|----------|-------|
| AWS Account | 257394478466 |
| Region | us-east-1 |
| VMAlert (Basic) | 10.238.3.153:8880 |
| DocumentDB Cluster Endpoint | `*.docdb.amazonaws.com:27017` |
| TLS CA Bundle | `global-bundle.pem` (download from AWS) |

---

## LCK-MG-001 â€” MongoCpuHigh_Warning

### Metadata / å…ƒæ•°æ®

```yaml
alert_id: "LCK-MG-001"
alert_name: "MongoCpuHigh_Warning"
severity: "warning"
tier: "2"
category: "db-mongo"
team: "dba"
first_responder: "US DBA"
old_ids_replaced: "ALR-030"
migration_action: "KEEP"
sla_response: "Tier 2: 15min acknowledge, 1h first update, 4h resolution"
skill_reference: "/app/skills/apm-alert-investigation.md"
last_updated: "2026-02-16"
```

### Alert Rule (from alert-rules-complete.yml) / å‘Šè­¦è§„åˆ™

```yaml
- alert: MongoCpuUsageWarning
  expr: |
    avg_over_time(mongodb_cpu_utilization{env="production"}[3m]) > 70
    and
    avg_over_time(mongodb_cpu_utilization{env="production"}[3m]) <= 90
  for: 5m
  labels:
    severity: "warning"
    tier: "2"
    team: "dba"
    category: "db-mongo"
    service: "documentdb-mongo"
  annotations:
    summary: "[LCK-NA-DB-MONGO] CpuUsage_Warning - {{ $labels.instance }}"
    impact: "MongoDB CPU elevated; query performance may degrade."
    notification_channel: "wecom+twilio-lead"
```

### 1. ASSESS (è¯„ä¼°) â€” First 2 Minutes / å‰2åˆ†é’Ÿ

**Goal / ç›®æ ‡:** Determine if MongoDB CPU impacts golden path and triage severity.
ç¡®å®š MongoDB CPU æ˜¯å¦å½±å“é»„é‡‘æµç¨‹å¹¶è¯„ä¼°ä¸¥é‡ç¨‹åº¦ã€‚

#### 1.1 Golden Path Impact Check / é»„é‡‘æµç¨‹å½±å“æ£€æŸ¥

```bash
# Check if completed orders are flowing / æ£€æŸ¥è®¢å•æ˜¯å¦æ­£å¸¸æµè½¬
# Datasource: df8o21agxtkw0d (UMBQuerier-Luckin)
curl -s "http://prometheus:9090/api/v1/query?query=sum_over_time(business_completed_orders_total[10m])"
# If == 0 for 10min â†’ Golden path DOWN â†’ escalate to Tier 3
# å¦‚æœ10åˆ†é’Ÿå†… == 0 â†’ é»„é‡‘æµç¨‹ä¸­æ–­ â†’ å‡çº§åˆ° Tier 3
```

#### 1.2 Quick Triage / å¿«é€Ÿåˆ†ç±»

```bash
# Current CPU value / å½“å‰ CPU å€¼
curl -s "http://prometheus:9090/api/v1/query?query=avg_over_time(mongodb_cpu_utilization{env='production'}[3m])" | jq '.data.result[] | {instance: .metric.instance, cpu: .value[1]}'

# Check if other Mongo alerts are firing / æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»– Mongo å‘Šè­¦è§¦å‘
curl -s "http://alertmanager:9093/api/v2/alerts?filter=category%3D%22db-mongo%22" | jq '.[].labels | {alertname, severity, instance}'
```

#### 1.3 Severity Classification / ä¸¥é‡ç¨‹åº¦åˆ†ç±»

| Condition / æ¡ä»¶ | Severity / ä¸¥é‡ç¨‹åº¦ | Action / æ“ä½œ |
|-----------|----------|--------|
| Golden path impacted (orders stopped) / é»„é‡‘æµç¨‹å—å½±å“ | **Critical -> Tier 3** | Wake China HQ / é€šçŸ¥ä¸­å›½æ€»éƒ¨ |
| CPU 70-90%, queries slow but orders flowing / CPU 70-90%ï¼ŒæŸ¥è¯¢å˜æ…¢ä½†è®¢å•æ­£å¸¸ | **Warning -> Tier 2** | US DBA investigates / US DBA è°ƒæŸ¥ |
| CPU spike already resolving / CPU å³°å€¼å·²åœ¨æ¢å¤ | **Info -> Tier 1** | Monitor trend / ç›‘æ§è¶‹åŠ¿ |

---

### 2. ACKNOWLEDGE (ç¡®è®¤) â€” Within 15 Minutes / 15åˆ†é’Ÿå†…

#### 2.1 Silence Alert / é™é»˜å‘Šè­¦

```bash
amtool silence add \
  alertname="MongoCpuUsageWarning" \
  category="db-mongo" \
  --duration="30m" \
  --comment="Investigating CPU warning - YOUR_NAME" \
  --author="YOUR_NAME"
```

#### 2.2 WeCom Notification / ä¼ä¸šå¾®ä¿¡é€šçŸ¥

```
ğŸ”” Alert Acknowledged / å‘Šè­¦å·²ç¡®è®¤
Alert: MongoCpuHigh_Warning (LCK-MG-001)
Severity: Warning | Tier: 2
Owner: {your_name}
Status: Investigating / è°ƒæŸ¥ä¸­
Instance: {instance}
CPU: {value}%
ETA for update: {time + 15min}
```

#### 2.3 SLA Timers / SLA æ—¶é—´è¦æ±‚

| Milestone / é‡Œç¨‹ç¢‘ | Deadline / æˆªæ­¢æ—¶é—´ |
|-----------|----------|
| Acknowledge / ç¡®è®¤ | 15 min |
| First Update / é¦–æ¬¡æ›´æ–° | 1 hour |
| Resolution / è§£å†³ | 4 hours |

---

### 3. ANALYZE (åˆ†æ) â€” Root Cause Investigation / æ ¹å› è°ƒæŸ¥

#### 3.1 Common Causes Checklist / å¸¸è§åŸå› æ¸…å•

```
[ ] Slow or unindexed queries / æ…¢æŸ¥è¯¢æˆ–ç¼ºå°‘ç´¢å¼•
[ ] Bulk write/import operation running / æ‰¹é‡å†™å…¥/å¯¼å…¥æ“ä½œè¿è¡Œä¸­
[ ] Index build in progress / ç´¢å¼•æ„å»ºè¿›è¡Œä¸­
[ ] Application connection storm / åº”ç”¨è¿æ¥é£æš´
[ ] Instance class undersized for workload / å®ä¾‹è§„æ ¼ä¸è¶³
```

#### 3.2 Diagnostic Commands / è¯Šæ–­å‘½ä»¤

```bash
# Connect to DocumentDB (TLS required) / è¿æ¥ DocumentDBï¼ˆéœ€è¦ TLSï¼‰
mongo --tls --host CLUSTER_ENDPOINT:27017 \
  --tlsCAFile global-bundle.pem \
  --username dbadmin --password PASSWORD

# Inside mongo shell / mongo shell å†…:

# Check current operations (find slow queries) / æ£€æŸ¥å½“å‰æ“ä½œï¼ˆæŸ¥æ‰¾æ…¢æŸ¥è¯¢ï¼‰
db.currentOp({"secs_running": {"$gt": 5}})

# Server status â€” connections and opcounters / æœåŠ¡å™¨çŠ¶æ€ â€” è¿æ¥æ•°å’Œæ“ä½œè®¡æ•°
db.serverStatus().connections
db.serverStatus().opcounters

# Check profiler for slow queries / æ£€æŸ¥åˆ†æå™¨ä¸­çš„æ…¢æŸ¥è¯¢
db.system.profile.find({"millis": {"$gt": 1000}}).sort({"ts": -1}).limit(10)

# Index usage stats / ç´¢å¼•ä½¿ç”¨ç»Ÿè®¡
db.COLLECTION_NAME.aggregate([{$indexStats: {}}])
```

```bash
# AWS CLI: CloudWatch CPU history / AWS CLI: CloudWatch CPU å†å²
aws cloudwatch get-metric-statistics \
  --namespace AWS/DocDB \
  --metric-name CPUUtilization \
  --dimensions Name=DBInstanceIdentifier,Value=INSTANCE_NAME \
  --start-time $(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%SZ) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \
  --period 60 --statistics Average --region us-east-1

# Check for recent instance events / æ£€æŸ¥æœ€è¿‘çš„å®ä¾‹äº‹ä»¶
aws docdb describe-events \
  --source-type db-instance \
  --duration 60 --region us-east-1
```

#### 3.3 Root Cause Decision Tree / æ ¹å› å†³ç­–æ ‘

```
CPU > 70%?
â”œâ”€ Yes â†’ Check currentOp for slow queries / æ£€æŸ¥ currentOp æ…¢æŸ¥è¯¢
â”‚  â”œâ”€ Slow queries found / å‘ç°æ…¢æŸ¥è¯¢ â†’ Check missing indexes / æ£€æŸ¥ç¼ºå¤±ç´¢å¼•
â”‚  â”‚  â”œâ”€ Missing index â†’ Create index (off-peak) / åˆ›å»ºç´¢å¼•ï¼ˆä½å³°æœŸï¼‰
â”‚  â”‚  â””â”€ Index exists â†’ Query optimization needed / éœ€è¦æŸ¥è¯¢ä¼˜åŒ–
â”‚  â””â”€ No slow queries / æ— æ…¢æŸ¥è¯¢ â†’ Check opcounters rate / æ£€æŸ¥æ“ä½œè®¡æ•°ç‡
â”‚     â”œâ”€ High insert/update rate â†’ Bulk operation in progress / æ‰¹é‡æ“ä½œè¿›è¡Œä¸­
â”‚     â””â”€ Normal rate â†’ Instance undersized / å®ä¾‹è§„æ ¼ä¸è¶³
â””â”€ No â†’ Alert may be resolving / å‘Šè­¦å¯èƒ½æ­£åœ¨æ¢å¤
```

---

### 4. ACT (è¡ŒåŠ¨) â€” Remediation / ä¿®å¤

#### 4.1 Tier 2 Actions (US DBA Authority) / Tier 2 æ“ä½œ

```bash
# Kill long-running operations / ç»ˆæ­¢é•¿æ—¶é—´è¿è¡Œçš„æ“ä½œ
# In mongo shell:
db.currentOp({"secs_running": {"$gt": 30}}).inprog.forEach(function(op) {
  db.killOp(op.opid);
  print("Killed op: " + op.opid + " running for " + op.secs_running + "s");
});

# Create missing index (if identified) / åˆ›å»ºç¼ºå¤±ç´¢å¼•ï¼ˆå¦‚æœå·²ç¡®è®¤ï¼‰
# WARNING: Index creation consumes CPU â€” schedule during low-traffic
# è­¦å‘Šï¼šç´¢å¼•åˆ›å»ºæ¶ˆè€— CPU â€” å®‰æ’åœ¨ä½æµé‡æ—¶æ®µ
db.COLLECTION.createIndex({"field": 1}, {"background": true})
```

#### 4.2 Escalation Criteria / å‡çº§æ ‡å‡†

| Condition / æ¡ä»¶ | Action / æ“ä½œ |
|-----------|--------|
| CPU stays > 70% after 30 min / CPU 30åˆ†é’Ÿåä» > 70% | Escalate to Tier 3 / å‡çº§åˆ° Tier 3 |
| CPU rises above 90% / CPU è¶…è¿‡ 90% | Auto-escalates to LCK-MG-002 (Critical) |
| Application errors increasing / åº”ç”¨é”™è¯¯å¢åŠ  | Escalate to Tier 3 / å‡çº§åˆ° Tier 3 |

```
Escalation path / å‡çº§è·¯å¾„:
US DBA â†’ (30 min no resolution) â†’ US DBA + Team Lead â†’ (30 min) â†’ China HQ DBA
```

---

### 5. AFTERMATH (å–„å) â€” Post-Incident / äº‹åå¤„ç†

#### 5.1 Prevention / é¢„é˜²

```
[ ] Review slow query log and add missing indexes / å®¡æŸ¥æ…¢æŸ¥è¯¢æ—¥å¿—å¹¶æ·»åŠ ç¼ºå¤±ç´¢å¼•
[ ] Evaluate if instance class needs upgrade / è¯„ä¼°æ˜¯å¦éœ€è¦å‡çº§å®ä¾‹è§„æ ¼
[ ] Check application query patterns for inefficiencies / æ£€æŸ¥åº”ç”¨æŸ¥è¯¢æ¨¡å¼æ˜¯å¦æœ‰ä½æ•ˆé—®é¢˜
[ ] Update threshold if alert too sensitive / å¦‚å‘Šè­¦è¿‡äºæ•æ„Ÿåˆ™æ›´æ–°é˜ˆå€¼
```

#### 5.2 Related Alerts / ç›¸å…³å‘Šè­¦

| Alert ID | Name | Relationship / å…³ç³» |
|----------|------|-------------|
| LCK-MG-002 | MongoCpuHigh_Critical | Escalation if CPU > 90% / CPU > 90% æ—¶å‡çº§ |
| LCK-MG-003 | MongoMemoryLow_Warning | CPU and memory often correlate / CPU å’Œå†…å­˜å¸¸ç›¸å…³ |
| LCK-MG-005 | MongoConnectionHigh_Warning | Connection storms cause CPU spikes / è¿æ¥é£æš´å¯¼è‡´ CPU å³°å€¼ |

#### 5.3 Knowledge Base Update / çŸ¥è¯†åº“æ›´æ–°

After resolution, update / è§£å†³åæ›´æ–°:
1. This runbook â€” add new root causes to Section 3.1 / å°†æ–°æ ¹å› æ·»åŠ åˆ° 3.1 èŠ‚
2. Alert thresholds â€” PR to `alert-rules-complete.yml` if needed / å¦‚éœ€è°ƒæ•´æäº¤ PR
3. Dashboard â€” add panel if visibility gap found / å¦‚å‘ç°å¯è§†åŒ–ç¼ºå£åˆ™æ·»åŠ é¢æ¿

---

## LCK-MG-002 â€” MongoCpuHigh_Critical

### Metadata / å…ƒæ•°æ®

```yaml
alert_id: "LCK-MG-002"
alert_name: "MongoCpuHigh_Critical"
severity: "critical"
tier: "3"
category: "db-mongo"
team: "dba"
first_responder: "US DBA + China HQ"
old_ids_replaced: "ALR-030, ALR-031"
migration_action: "MERGE"
sla_response: "Tier 3: 5min acknowledge, 15min first update, 1h resolution"
skill_reference: "/app/skills/apm-alert-investigation.md"
last_updated: "2026-02-16"
```

> **Note / æ³¨æ„:** The YAML rule has `tier: "1"` but the alert inventory assigns Tier 3 per the SLA framework
> (Critical = Tier 3 = 5min acknowledge). This runbook follows the inventory Tier 3 assignment.
> YAML è§„åˆ™ä¸­ `tier: "1"` ä½†å‘Šè­¦æ¸…å•æŒ‰ SLA æ¡†æ¶åˆ†é…ä¸º Tier 3ï¼ˆCritical = Tier 3 = 5åˆ†é’Ÿç¡®è®¤ï¼‰ã€‚
> æœ¬æ‰‹å†Œéµå¾ªæ¸…å•ä¸­çš„ Tier 3 åˆ†é…ã€‚

### Alert Rule (from alert-rules-complete.yml) / å‘Šè­¦è§„åˆ™

```yaml
- alert: MongoCpuUsageCritical
  expr: |
    avg_over_time(mongodb_cpu_utilization{env="production"}[3m]) > 90
  for: 3m
  labels:
    severity: "critical"
    tier: "1"
    team: "dba"
    category: "db-mongo"
    service: "documentdb-mongo"
  annotations:
    summary: "[LCK-NA-DB-MONGO] CpuUsage_Critical - {{ $labels.instance }}"
    impact: "MongoDB CPU critical; operations timing out, service degradation imminent."
    notification_channel: "wecom+twilio-all"
```

### 1. ASSESS (è¯„ä¼°) â€” First 2 Minutes / å‰2åˆ†é’Ÿ

**Goal / ç›®æ ‡:** Confirm critical CPU state and determine golden path impact immediately.
ç«‹å³ç¡®è®¤å…³é”® CPU çŠ¶æ€å¹¶ç¡®å®šå¯¹é»„é‡‘æµç¨‹çš„å½±å“ã€‚

#### 1.1 Golden Path Impact Check / é»„é‡‘æµç¨‹å½±å“æ£€æŸ¥

```bash
# IMMEDIATE: Check order flow / ç«‹å³æ£€æŸ¥è®¢å•æµ
curl -s "http://prometheus:9090/api/v1/query?query=sum_over_time(business_completed_orders_total[10m])"
# If == 0 â†’ CRITICAL: Golden path DOWN / å¦‚æœ == 0 â†’ ä¸¥é‡ï¼šé»„é‡‘æµç¨‹ä¸­æ–­

# Check current CPU / æ£€æŸ¥å½“å‰ CPU
curl -s "http://prometheus:9090/api/v1/query?query=avg_over_time(mongodb_cpu_utilization{env='production'}[3m])" | jq '.data.result[] | {instance: .metric.instance, cpu: .value[1]}'
```

#### 1.2 Quick Triage / å¿«é€Ÿåˆ†ç±»

```bash
# Is this a single instance or cluster-wide? / æ˜¯å•å®ä¾‹è¿˜æ˜¯é›†ç¾¤èŒƒå›´ï¼Ÿ
curl -s "http://prometheus:9090/api/v1/query?query=mongodb_cpu_utilization{env='production'}" | jq '.data.result[] | {instance: .metric.instance, cpu: .value[1]}'

# Check all Mongo alerts firing / æ£€æŸ¥æ‰€æœ‰è§¦å‘çš„ Mongo å‘Šè­¦
curl -s "http://alertmanager:9093/api/v2/alerts?filter=category%3D%22db-mongo%22" | jq '.[].labels | {alertname, severity, instance}'
```

#### 1.3 Severity Classification / ä¸¥é‡ç¨‹åº¦åˆ†ç±»

| Condition / æ¡ä»¶ | Severity / ä¸¥é‡ç¨‹åº¦ | Action / æ“ä½œ |
|-----------|----------|--------|
| Golden path DOWN + CPU > 90% | **Critical -> Tier 3** | Wake ALL: China HQ + US DevOps / é€šçŸ¥æ‰€æœ‰äºº |
| CPU > 90% but orders flowing | **Critical -> Tier 3** | US DBA + China HQ coordinate / åè°ƒå¤„ç† |
| CPU dropping back below 90% | **Reassess as Warning** | May downgrade to LCK-MG-001 / å¯èƒ½é™çº§ |

---

### 2. ACKNOWLEDGE (ç¡®è®¤) â€” Within 5 Minutes / 5åˆ†é’Ÿå†…

#### 2.1 Silence Alert / é™é»˜å‘Šè­¦

```bash
amtool silence add \
  alertname="MongoCpuUsageCritical" \
  category="db-mongo" \
  --duration="15m" \
  --comment="CRITICAL: Investigating CPU > 90% - YOUR_NAME" \
  --author="YOUR_NAME"
```

#### 2.2 WeCom Notification / ä¼ä¸šå¾®ä¿¡é€šçŸ¥

```
ğŸš¨ CRITICAL Alert Acknowledged / ä¸¥é‡å‘Šè­¦å·²ç¡®è®¤
Alert: MongoCpuHigh_Critical (LCK-MG-002)
Severity: CRITICAL | Tier: 3
Owner: {your_name}
Status: Investigating / è°ƒæŸ¥ä¸­
Instance: {instance}
CPU: {value}% (> 90%)
Golden Path: {OK/IMPACTED}
ETA for update: {time + 15min}
China HQ notified: YES / å·²é€šçŸ¥ä¸­å›½æ€»éƒ¨: æ˜¯
```

#### 2.3 SLA Timers / SLA æ—¶é—´è¦æ±‚

| Milestone / é‡Œç¨‹ç¢‘ | Deadline / æˆªæ­¢æ—¶é—´ |
|-----------|----------|
| Acknowledge / ç¡®è®¤ | **5 min** |
| First Update / é¦–æ¬¡æ›´æ–° | **15 min** |
| Resolution / è§£å†³ | **1 hour** |

---

### 3. ANALYZE (åˆ†æ) â€” Root Cause Investigation / æ ¹å› è°ƒæŸ¥

#### 3.1 Common Causes Checklist / å¸¸è§åŸå› æ¸…å•

```
[ ] Runaway query consuming all CPU / å¤±æ§æŸ¥è¯¢æ¶ˆè€—æ‰€æœ‰ CPU
[ ] Index build on large collection / å¤§é›†åˆä¸Šçš„ç´¢å¼•æ„å»º
[ ] Bulk data migration or ETL job / æ‰¹é‡æ•°æ®è¿ç§»æˆ– ETL ä½œä¸š
[ ] Connection storm from application restart / åº”ç”¨é‡å¯å¯¼è‡´çš„è¿æ¥é£æš´
[ ] Instance class too small for current workload / å®ä¾‹è§„æ ¼å¯¹å½“å‰è´Ÿè½½è¿‡å°
[ ] Background maintenance (compaction) / åå°ç»´æŠ¤ï¼ˆå‹ç¼©ï¼‰
```

#### 3.2 Diagnostic Commands / è¯Šæ–­å‘½ä»¤

```bash
# Connect to DocumentDB / è¿æ¥ DocumentDB
mongo --tls --host CLUSTER_ENDPOINT:27017 \
  --tlsCAFile global-bundle.pem \
  --username dbadmin --password PASSWORD

# IMMEDIATE: Find CPU-burning operations / ç«‹å³æŸ¥æ‰¾æ¶ˆè€— CPU çš„æ“ä½œ
db.currentOp({"secs_running": {"$gt": 3}})

# Check opcounters for abnormal rates / æ£€æŸ¥æ“ä½œè®¡æ•°å™¨æ˜¯å¦å¼‚å¸¸
db.serverStatus().opcounters

# Connection count (connection storm?) / è¿æ¥æ•°ï¼ˆè¿æ¥é£æš´ï¼Ÿï¼‰
db.serverStatus().connections

# Profiler: slowest queries in last 10 min / åˆ†æå™¨ï¼šæœ€è¿‘10åˆ†é’Ÿæœ€æ…¢æŸ¥è¯¢
db.system.profile.find({"millis": {"$gt": 500}}).sort({"ts": -1}).limit(20)

# Collection scan detection / å…¨è¡¨æ‰«ææ£€æµ‹
db.system.profile.find({"planSummary": "COLLSCAN"}).sort({"ts": -1}).limit(10)
```

```bash
# AWS CLI: CPU spike timeline / AWS CLI: CPU å³°å€¼æ—¶é—´çº¿
aws cloudwatch get-metric-statistics \
  --namespace AWS/DocDB \
  --metric-name CPUUtilization \
  --dimensions Name=DBInstanceIdentifier,Value=INSTANCE_NAME \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \
  --period 60 --statistics Average,Maximum --region us-east-1

# Check for recent DocumentDB events / æ£€æŸ¥æœ€è¿‘çš„ DocumentDB äº‹ä»¶
aws docdb describe-events \
  --source-type db-instance \
  --duration 120 --region us-east-1

# Instance class (check if undersized) / å®ä¾‹è§„æ ¼ï¼ˆæ£€æŸ¥æ˜¯å¦ä¸è¶³ï¼‰
aws docdb describe-db-instances --region us-east-1 | \
  jq '.DBInstances[] | {id: .DBInstanceIdentifier, class: .DBInstanceClass, status: .DBInstanceStatus}'
```

---

### 4. ACT (è¡ŒåŠ¨) â€” Remediation / ä¿®å¤

#### 4.1 Tier 3 Actions (US DBA + China HQ) / Tier 3 æ“ä½œ

```bash
# IMMEDIATE: Kill all long-running operations / ç«‹å³ç»ˆæ­¢æ‰€æœ‰é•¿æ—¶é—´è¿è¡Œçš„æ“ä½œ
db.currentOp({"secs_running": {"$gt": 10}}).inprog.forEach(function(op) {
  db.killOp(op.opid);
  print("KILLED op: " + op.opid + " ns: " + op.ns + " running: " + op.secs_running + "s");
});

# If application is flooding connections / å¦‚æœåº”ç”¨å¤§é‡æ¶Œå…¥è¿æ¥:
# Coordinate with application team to reduce connection pool size
# ä¸åº”ç”¨å›¢é˜Ÿåè°ƒå‡å°‘è¿æ¥æ± å¤§å°

# Emergency: Scale up instance class (requires China HQ approval)
# ç´§æ€¥ï¼šå‡çº§å®ä¾‹è§„æ ¼ï¼ˆéœ€è¦ä¸­å›½æ€»éƒ¨æ‰¹å‡†ï¼‰
aws docdb modify-db-instance \
  --db-instance-identifier INSTANCE_NAME \
  --db-instance-class db.r6g.xlarge \
  --apply-immediately --region us-east-1
# WARNING: Instance will reboot during class change! / è­¦å‘Šï¼šæ›´æ”¹è§„æ ¼æœŸé—´å®ä¾‹å°†é‡å¯ï¼

# Add read replica to offload reads (if read-heavy) / æ·»åŠ åªè¯»å‰¯æœ¬åˆ†æµè¯»å–ï¼ˆå¦‚æœè¯»å–å¯†é›†ï¼‰
aws docdb create-db-instance \
  --db-instance-identifier INSTANCE_NAME-reader \
  --db-instance-class db.r6g.large \
  --db-cluster-identifier CLUSTER_NAME \
  --region us-east-1
```

#### 4.2 Escalation Criteria / å‡çº§æ ‡å‡†

| Condition / æ¡ä»¶ | Action / æ“ä½œ |
|-----------|--------|
| CPU > 90% after 15 min of remediation / ä¿®å¤15åˆ†é’Ÿå CPU ä» > 90% | Failover to replica / æ•…éšœè½¬ç§»åˆ°å‰¯æœ¬ |
| Golden path impacted / é»„é‡‘æµç¨‹å—å½±å“ | All hands â€” US + China HQ / å…¨å‘˜ â€” US + ä¸­å›½æ€»éƒ¨ |
| Cannot identify root cause in 30 min / 30åˆ†é’Ÿå†…æ— æ³•ç¡®å®šæ ¹å›  | Engage AWS Support / è”ç³» AWS æ”¯æŒ |

```bash
# Emergency failover (LAST RESORT) / ç´§æ€¥æ•…éšœè½¬ç§»ï¼ˆæœ€åæ‰‹æ®µï¼‰
aws docdb failover-db-cluster \
  --db-cluster-identifier CLUSTER_NAME \
  --region us-east-1
# This promotes a replica to primary / è¿™å°†æŠŠå‰¯æœ¬æå‡ä¸ºä¸»èŠ‚ç‚¹
```

---

### 5. AFTERMATH (å–„å) â€” Post-Incident / äº‹åå¤„ç†

#### 5.1 Prevention / é¢„é˜²

```
[ ] Mandatory incident report within 24 hours / 24å°æ—¶å†…å¿…é¡»æäº¤äº‹ä»¶æŠ¥å‘Š
[ ] Root cause analysis with application team / ä¸åº”ç”¨å›¢é˜Ÿè¿›è¡Œæ ¹å› åˆ†æ
[ ] Index audit on affected collections / å¯¹å—å½±å“é›†åˆè¿›è¡Œç´¢å¼•å®¡è®¡
[ ] Load test to validate capacity / è´Ÿè½½æµ‹è¯•éªŒè¯å®¹é‡
[ ] Evaluate instance class upgrade (permanent) / è¯„ä¼°å®ä¾‹è§„æ ¼å‡çº§ï¼ˆæ°¸ä¹…ï¼‰
[ ] Review application query patterns / å®¡æŸ¥åº”ç”¨æŸ¥è¯¢æ¨¡å¼
```

#### 5.2 Related Alerts / ç›¸å…³å‘Šè­¦

| Alert ID | Name | Relationship / å…³ç³» |
|----------|------|-------------|
| LCK-MG-001 | MongoCpuHigh_Warning | Warning precursor to this alert / æ­¤å‘Šè­¦çš„é¢„è­¦å‰å…† |
| LCK-MG-003 | MongoMemoryLow_Warning | CPU stress often causes memory pressure / CPU å‹åŠ›å¸¸å¯¼è‡´å†…å­˜å‹åŠ› |
| LCK-MG-004 | MongoMemoryLow_Critical | May fire simultaneously / å¯èƒ½åŒæ—¶è§¦å‘ |
| LCK-MG-005 | MongoConnectionHigh_Warning | Connection storms cause CPU spikes / è¿æ¥é£æš´å¯¼è‡´ CPU å³°å€¼ |

#### 5.3 Knowledge Base Update / çŸ¥è¯†åº“æ›´æ–°

After resolution, update / è§£å†³åæ›´æ–°:
1. This runbook â€” add new root causes and effective remediations / æ·»åŠ æ–°æ ¹å› å’Œæœ‰æ•ˆä¿®å¤æªæ–½
2. Incident report â€” file in `/app/alertrebuild/incidents/` / åœ¨äº‹ä»¶ç›®å½•ä¸­å½’æ¡£
3. Alert thresholds â€” PR to `alert-rules-complete.yml` if needed / å¦‚éœ€è°ƒæ•´æäº¤ PR
4. Capacity plan â€” update DocumentDB sizing recommendations / æ›´æ–° DocumentDB å®¹é‡è§„åˆ’å»ºè®®

---

## LCK-MG-003 â€” MongoMemoryLow_Warning

### Metadata / å…ƒæ•°æ®

```yaml
alert_id: "LCK-MG-003"
alert_name: "MongoMemoryLow_Warning"
severity: "warning"
tier: "2"
category: "db-mongo"
team: "dba"
first_responder: "US DBA"
old_ids_replaced: "ALR-032"
migration_action: "KEEP"
sla_response: "Tier 2: 15min acknowledge, 1h first update, 4h resolution"
skill_reference: "/app/skills/apm-alert-investigation.md"
last_updated: "2026-02-16"
```

### Alert Rule (from alert-rules-complete.yml) / å‘Šè­¦è§„åˆ™

```yaml
- alert: MongoMemoryFreeWarning
  expr: |
    mongodb_freeable_memory_bytes{env="production"} / 1024 / 1024 < 500
    and
    mongodb_freeable_memory_bytes{env="production"} / 1024 / 1024 >= 200
  for: 5m
  labels:
    severity: "warning"
    tier: "2"
    team: "dba"
    category: "db-mongo"
    service: "documentdb-mongo"
  annotations:
    summary: "[LCK-NA-DB-MONGO] MemoryFreeLow_Warning - {{ $labels.instance }}"
    impact: "MongoDB freeable memory low; swap usage may increase, performance degrades."
    notification_channel: "wecom+twilio-lead"
```

### 1. ASSESS (è¯„ä¼°) â€” First 2 Minutes / å‰2åˆ†é’Ÿ

**Goal / ç›®æ ‡:** Determine memory consumption source and assess impact.
ç¡®å®šå†…å­˜æ¶ˆè€—æ¥æºå¹¶è¯„ä¼°å½±å“ã€‚

#### 1.1 Golden Path Impact Check / é»„é‡‘æµç¨‹å½±å“æ£€æŸ¥

```bash
# Check order flow / æ£€æŸ¥è®¢å•æµ
curl -s "http://prometheus:9090/api/v1/query?query=sum_over_time(business_completed_orders_total[10m])"
```

#### 1.2 Quick Triage / å¿«é€Ÿåˆ†ç±»

```bash
# Current freeable memory / å½“å‰å¯ç”¨å†…å­˜
curl -s "http://prometheus:9090/api/v1/query?query=mongodb_freeable_memory_bytes{env='production'}/1024/1024" | jq '.data.result[] | {instance: .metric.instance, memory_mb: .value[1]}'

# Memory trend (last 1h) / å†…å­˜è¶‹åŠ¿ï¼ˆæœ€è¿‘1å°æ—¶ï¼‰
# Check in Grafana: https://grafana.luckinus.com/d/mongo-memory
```

#### 1.3 Severity Classification / ä¸¥é‡ç¨‹åº¦åˆ†ç±»

| Condition / æ¡ä»¶ | Severity / ä¸¥é‡ç¨‹åº¦ | Action / æ“ä½œ |
|-----------|----------|--------|
| Memory < 500MB, trending down fast / å†…å­˜ < 500MB ä¸”å¿«é€Ÿä¸‹é™ | **Warning -> Tier 2** | Investigate immediately / ç«‹å³è°ƒæŸ¥ |
| Memory < 500MB, stable / å†…å­˜ < 500MBï¼Œç¨³å®š | **Warning -> Tier 2** | Investigate and plan / è°ƒæŸ¥å¹¶åˆ¶å®šè®¡åˆ’ |
| Memory recovering (> 500MB) / å†…å­˜æ¢å¤ä¸­ | **Resolving** | Monitor / ç›‘æ§ |

---

### 2. ACKNOWLEDGE (ç¡®è®¤) â€” Within 15 Minutes / 15åˆ†é’Ÿå†…

#### 2.1 Silence Alert / é™é»˜å‘Šè­¦

```bash
amtool silence add \
  alertname="MongoMemoryFreeWarning" \
  category="db-mongo" \
  --duration="30m" \
  --comment="Investigating low memory - YOUR_NAME" \
  --author="YOUR_NAME"
```

#### 2.2 WeCom Notification / ä¼ä¸šå¾®ä¿¡é€šçŸ¥

```
ğŸ”” Alert Acknowledged / å‘Šè­¦å·²ç¡®è®¤
Alert: MongoMemoryLow_Warning (LCK-MG-003)
Severity: Warning | Tier: 2
Owner: {your_name}
Status: Investigating / è°ƒæŸ¥ä¸­
Instance: {instance}
Freeable Memory: {value}MB (threshold: < 500MB)
ETA for update: {time + 15min}
```

#### 2.3 SLA Timers / SLA æ—¶é—´è¦æ±‚

| Milestone / é‡Œç¨‹ç¢‘ | Deadline / æˆªæ­¢æ—¶é—´ |
|-----------|----------|
| Acknowledge / ç¡®è®¤ | 15 min |
| First Update / é¦–æ¬¡æ›´æ–° | 1 hour |
| Resolution / è§£å†³ | 4 hours |

---

### 3. ANALYZE (åˆ†æ) â€” Root Cause Investigation / æ ¹å› è°ƒæŸ¥

#### 3.1 Common Causes Checklist / å¸¸è§åŸå› æ¸…å•

```
[ ] Working set exceeds available memory / å·¥ä½œé›†è¶…è¿‡å¯ç”¨å†…å­˜
[ ] Large sort operations spilling to disk / å¤§æ’åºæ“ä½œæº¢å‡ºåˆ°ç£ç›˜
[ ] Too many open cursors / æ‰“å¼€çš„æ¸¸æ ‡è¿‡å¤š
[ ] Memory leak in application connection pool / åº”ç”¨è¿æ¥æ± å†…å­˜æ³„æ¼
[ ] Instance class too small / å®ä¾‹è§„æ ¼è¿‡å°
[ ] Swap usage increasing (performance degradation) / äº¤æ¢ä½¿ç”¨å¢åŠ ï¼ˆæ€§èƒ½ä¸‹é™ï¼‰
```

#### 3.2 Diagnostic Commands / è¯Šæ–­å‘½ä»¤

```bash
# Connect to DocumentDB / è¿æ¥ DocumentDB
mongo --tls --host CLUSTER_ENDPOINT:27017 \
  --tlsCAFile global-bundle.pem \
  --username dbadmin --password PASSWORD

# Check server status â€” memory section / æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€ â€” å†…å­˜éƒ¨åˆ†
db.serverStatus().mem

# Connection count (each connection uses memory) / è¿æ¥æ•°ï¼ˆæ¯ä¸ªè¿æ¥å ç”¨å†…å­˜ï¼‰
db.serverStatus().connections

# Check for large sort operations / æ£€æŸ¥å¤§æ’åºæ“ä½œ
db.currentOp({"secs_running": {"$gt": 5}})

# Collection sizes (identify memory pressure source) / é›†åˆå¤§å°ï¼ˆè¯†åˆ«å†…å­˜å‹åŠ›æ¥æºï¼‰
db.getCollectionNames().forEach(function(c) {
  var stats = db.getCollection(c).stats();
  print(c + ": " + Math.round(stats.size/1024/1024) + "MB, indexes: " + Math.round(stats.totalIndexSize/1024/1024) + "MB");
});
```

```bash
# AWS CLI: Memory metrics / AWS CLI: å†…å­˜æŒ‡æ ‡
aws cloudwatch get-metric-statistics \
  --namespace AWS/DocDB \
  --metric-name FreeableMemory \
  --dimensions Name=DBInstanceIdentifier,Value=INSTANCE_NAME \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \
  --period 60 --statistics Minimum,Average --region us-east-1

# Swap usage / äº¤æ¢ä½¿ç”¨é‡
aws cloudwatch get-metric-statistics \
  --namespace AWS/DocDB \
  --metric-name SwapUsage \
  --dimensions Name=DBInstanceIdentifier,Value=INSTANCE_NAME \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \
  --period 60 --statistics Maximum --region us-east-1
```

#### 3.3 Root Cause Decision Tree / æ ¹å› å†³ç­–æ ‘

```
Freeable Memory < 500MB?
â”œâ”€ Yes â†’ Check connections count / æ£€æŸ¥è¿æ¥æ•°
â”‚  â”œâ”€ Connections high (> 80% max) â†’ Connection pool issue / è¿æ¥æ± é—®é¢˜ â†’ See LCK-MG-005
â”‚  â””â”€ Connections normal / è¿æ¥æ­£å¸¸ â†’ Check collection sizes / æ£€æŸ¥é›†åˆå¤§å°
â”‚     â”œâ”€ Working set growing â†’ Instance class upgrade needed / éœ€è¦å‡çº§å®ä¾‹è§„æ ¼
â”‚     â””â”€ Working set stable â†’ Check for sort spills / æ£€æŸ¥æ’åºæº¢å‡º
â”‚        â”œâ”€ Sort spills â†’ Add indexes for sort operations / ä¸ºæ’åºæ“ä½œæ·»åŠ ç´¢å¼•
â”‚        â””â”€ No spills â†’ Monitor, may need more memory / ç›‘æ§ï¼Œå¯èƒ½éœ€è¦æ›´å¤šå†…å­˜
â””â”€ No â†’ Alert resolving / å‘Šè­¦æ¢å¤ä¸­
```

---

### 4. ACT (è¡ŒåŠ¨) â€” Remediation / ä¿®å¤

#### 4.1 Tier 2 Actions (US DBA Authority) / Tier 2 æ“ä½œ

```bash
# Kill memory-intensive operations / ç»ˆæ­¢å†…å­˜å¯†é›†æ“ä½œ
db.currentOp({"secs_running": {"$gt": 30}}).inprog.forEach(function(op) {
  db.killOp(op.opid);
});

# Close idle cursors / å…³é—­ç©ºé—²æ¸¸æ ‡
# (DocumentDB manages cursor timeout automatically at 10 min)
# (DocumentDB è‡ªåŠ¨ç®¡ç†æ¸¸æ ‡è¶…æ—¶ï¼Œ10åˆ†é’Ÿ)

# If connection pool is the issue, coordinate with app team to:
# å¦‚æœè¿æ¥æ± æ˜¯é—®é¢˜ï¼Œä¸åº”ç”¨å›¢é˜Ÿåè°ƒ:
# - Reduce maxPoolSize / å‡å°‘ maxPoolSize
# - Enable connection pool monitoring / å¯ç”¨è¿æ¥æ± ç›‘æ§
```

#### 4.2 Escalation Criteria / å‡çº§æ ‡å‡†

| Condition / æ¡ä»¶ | Action / æ“ä½œ |
|-----------|--------|
| Memory drops below 200MB / å†…å­˜é™åˆ° 200MB ä»¥ä¸‹ | Auto-escalates to LCK-MG-004 (Critical) |
| Swap usage > 100MB / äº¤æ¢ä½¿ç”¨ > 100MB | Escalate to Tier 3 / å‡çº§åˆ° Tier 3 |
| Performance visibly degraded / æ€§èƒ½æ˜æ˜¾ä¸‹é™ | Escalate to Tier 3 / å‡çº§åˆ° Tier 3 |

---

### 5. AFTERMATH (å–„å) â€” Post-Incident / äº‹åå¤„ç†

#### 5.1 Prevention / é¢„é˜²

```
[ ] Review instance sizing vs working set / å®¡æŸ¥å®ä¾‹è§„æ ¼ä¸å·¥ä½œé›†å¤§å°
[ ] Implement memory usage trending dashboard / å®æ–½å†…å­˜ä½¿ç”¨è¶‹åŠ¿ä»ªè¡¨æ¿
[ ] Add indexes for queries causing sort spills / ä¸ºå¯¼è‡´æ’åºæº¢å‡ºçš„æŸ¥è¯¢æ·»åŠ ç´¢å¼•
[ ] Review application connection pool settings / å®¡æŸ¥åº”ç”¨è¿æ¥æ± è®¾ç½®
```

#### 5.2 Related Alerts / ç›¸å…³å‘Šè­¦

| Alert ID | Name | Relationship / å…³ç³» |
|----------|------|-------------|
| LCK-MG-004 | MongoMemoryLow_Critical | Escalation if memory < 200MB / å†…å­˜ < 200MB æ—¶å‡çº§ |
| LCK-MG-001 | MongoCpuHigh_Warning | Low memory causes more CPU (swapping) / ä½å†…å­˜å¯¼è‡´æ›´å¤š CPUï¼ˆäº¤æ¢ï¼‰ |
| LCK-MG-005 | MongoConnectionHigh_Warning | Connections consume memory / è¿æ¥æ¶ˆè€—å†…å­˜ |

---

## LCK-MG-004 â€” MongoMemoryLow_Critical

### Metadata / å…ƒæ•°æ®

```yaml
alert_id: "LCK-MG-004"
alert_name: "MongoMemoryLow_Critical"
severity: "critical"
tier: "3"
category: "db-mongo"
team: "dba"
first_responder: "US DBA + China HQ"
old_ids_replaced: "ALR-032"
migration_action: "SPLIT"
sla_response: "Tier 3: 5min acknowledge, 15min first update, 1h resolution"
skill_reference: "/app/skills/apm-alert-investigation.md"
last_updated: "2026-02-16"
```

> **Note / æ³¨æ„:** The YAML rule has `tier: "1"` but the alert inventory assigns Tier 3 per the SLA framework
> (Critical = Tier 3 = 5min acknowledge). This runbook follows the inventory Tier 3 assignment.
> YAML è§„åˆ™ä¸­ `tier: "1"` ä½†å‘Šè­¦æ¸…å•æŒ‰ SLA æ¡†æ¶åˆ†é…ä¸º Tier 3ï¼ˆCritical = Tier 3 = 5åˆ†é’Ÿç¡®è®¤ï¼‰ã€‚
> æœ¬æ‰‹å†Œéµå¾ªæ¸…å•ä¸­çš„ Tier 3 åˆ†é…ã€‚

### Alert Rule (from alert-rules-complete.yml) / å‘Šè­¦è§„åˆ™

```yaml
- alert: MongoMemoryFreeCritical
  expr: |
    mongodb_freeable_memory_bytes{env="production"} / 1024 / 1024 < 200
  for: 3m
  labels:
    severity: "critical"
    tier: "1"
    team: "dba"
    category: "db-mongo"
    service: "documentdb-mongo"
  annotations:
    summary: "[LCK-NA-DB-MONGO] MemoryFreeLow_Critical - {{ $labels.instance }}"
    impact: "MongoDB memory critically low; OOM kill risk, potential instance crash."
    notification_channel: "wecom+twilio-all"
```

### 1. ASSESS (è¯„ä¼°) â€” First 2 Minutes / å‰2åˆ†é’Ÿ

**Goal / ç›®æ ‡:** Confirm critical memory state and assess OOM risk immediately.
ç«‹å³ç¡®è®¤å…³é”®å†…å­˜çŠ¶æ€å¹¶è¯„ä¼° OOM é£é™©ã€‚

#### 1.1 Golden Path Impact Check / é»„é‡‘æµç¨‹å½±å“æ£€æŸ¥

```bash
# IMMEDIATE: Check order flow / ç«‹å³æ£€æŸ¥è®¢å•æµ
curl -s "http://prometheus:9090/api/v1/query?query=sum_over_time(business_completed_orders_total[10m])"

# Check current freeable memory / æ£€æŸ¥å½“å‰å¯ç”¨å†…å­˜
curl -s "http://prometheus:9090/api/v1/query?query=mongodb_freeable_memory_bytes{env='production'}/1024/1024" | jq '.data.result[] | {instance: .metric.instance, memory_mb: .value[1]}'
```

#### 1.2 Quick Triage / å¿«é€Ÿåˆ†ç±»

```bash
# Check swap usage (DocumentDB may be swapping) / æ£€æŸ¥äº¤æ¢ä½¿ç”¨ï¼ˆDocumentDB å¯èƒ½åœ¨äº¤æ¢ï¼‰
aws cloudwatch get-metric-statistics \
  --namespace AWS/DocDB \
  --metric-name SwapUsage \
  --dimensions Name=DBInstanceIdentifier,Value=INSTANCE_NAME \
  --start-time $(date -u -d '15 minutes ago' +%Y-%m-%dT%H:%M:%SZ) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \
  --period 60 --statistics Maximum --region us-east-1
```

#### 1.3 Severity Classification / ä¸¥é‡ç¨‹åº¦åˆ†ç±»

| Condition / æ¡ä»¶ | Severity / ä¸¥é‡ç¨‹åº¦ | Action / æ“ä½œ |
|-----------|----------|--------|
| Memory < 200MB + golden path down / å†…å­˜ < 200MB + é»„é‡‘æµç¨‹ä¸­æ–­ | **Critical -> Tier 3** | All hands â€” emergency / å…¨å‘˜ â€” ç´§æ€¥ |
| Memory < 200MB + orders flowing / å†…å­˜ < 200MB + è®¢å•æ­£å¸¸ | **Critical -> Tier 3** | US DBA + China HQ / ç´§æ€¥å¤„ç† |
| Memory recovering above 200MB / å†…å­˜æ¢å¤è‡³ 200MB ä»¥ä¸Š | **Reassess as Warning** | May downgrade to LCK-MG-003 |

---

### 2. ACKNOWLEDGE (ç¡®è®¤) â€” Within 5 Minutes / 5åˆ†é’Ÿå†…

#### 2.1 Silence Alert / é™é»˜å‘Šè­¦

```bash
amtool silence add \
  alertname="MongoMemoryFreeCritical" \
  category="db-mongo" \
  --duration="15m" \
  --comment="CRITICAL: Memory < 200MB, OOM risk - YOUR_NAME" \
  --author="YOUR_NAME"
```

#### 2.2 WeCom Notification / ä¼ä¸šå¾®ä¿¡é€šçŸ¥

```
ğŸš¨ CRITICAL Alert Acknowledged / ä¸¥é‡å‘Šè­¦å·²ç¡®è®¤
Alert: MongoMemoryLow_Critical (LCK-MG-004)
Severity: CRITICAL | Tier: 3
Owner: {your_name}
Status: Investigating / è°ƒæŸ¥ä¸­
Instance: {instance}
Freeable Memory: {value}MB (threshold: < 200MB) â€” OOM RISK
Golden Path: {OK/IMPACTED}
ETA for update: {time + 15min}
China HQ notified: YES / å·²é€šçŸ¥ä¸­å›½æ€»éƒ¨: æ˜¯
```

#### 2.3 SLA Timers / SLA æ—¶é—´è¦æ±‚

| Milestone / é‡Œç¨‹ç¢‘ | Deadline / æˆªæ­¢æ—¶é—´ |
|-----------|----------|
| Acknowledge / ç¡®è®¤ | **5 min** |
| First Update / é¦–æ¬¡æ›´æ–° | **15 min** |
| Resolution / è§£å†³ | **1 hour** |

---

### 3. ANALYZE (åˆ†æ) â€” Root Cause Investigation / æ ¹å› è°ƒæŸ¥

#### 3.1 Common Causes Checklist / å¸¸è§åŸå› æ¸…å•

```
[ ] Working set far exceeds instance memory / å·¥ä½œé›†è¿œè¶…å®ä¾‹å†…å­˜
[ ] Memory leak from application connections / åº”ç”¨è¿æ¥å†…å­˜æ³„æ¼
[ ] Massive sort/aggregation operations / å¤§é‡æ’åº/èšåˆæ“ä½œ
[ ] Connection count explosion / è¿æ¥æ•°çˆ†å‘
[ ] Instance class severely undersized / å®ä¾‹è§„æ ¼ä¸¥é‡ä¸è¶³
[ ] Swap exhaustion approaching OOM / äº¤æ¢è€—å°½æ¥è¿‘ OOM
```

#### 3.2 Diagnostic Commands / è¯Šæ–­å‘½ä»¤

```bash
# Connect to DocumentDB / è¿æ¥ DocumentDB
mongo --tls --host CLUSTER_ENDPOINT:27017 \
  --tlsCAFile global-bundle.pem \
  --username dbadmin --password PASSWORD

# IMMEDIATE: Check memory and connections / ç«‹å³æ£€æŸ¥å†…å­˜å’Œè¿æ¥
db.serverStatus().mem
db.serverStatus().connections

# Kill all non-essential operations / ç»ˆæ­¢æ‰€æœ‰éå¿…è¦æ“ä½œ
db.currentOp({"secs_running": {"$gt": 5}}).inprog.forEach(function(op) {
  if (op.ns !== "admin.$cmd") {
    db.killOp(op.opid);
    print("KILLED: " + op.opid + " ns: " + op.ns);
  }
});
```

```bash
# AWS CLI: Memory + swap timeline / AWS CLI: å†…å­˜ + äº¤æ¢æ—¶é—´çº¿
aws cloudwatch get-metric-statistics \
  --namespace AWS/DocDB \
  --metric-name FreeableMemory \
  --dimensions Name=DBInstanceIdentifier,Value=INSTANCE_NAME \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \
  --period 60 --statistics Minimum --region us-east-1

# Check current instance class / æ£€æŸ¥å½“å‰å®ä¾‹è§„æ ¼
aws docdb describe-db-instances --region us-east-1 | \
  jq '.DBInstances[] | {id: .DBInstanceIdentifier, class: .DBInstanceClass, status: .DBInstanceStatus}'
```

---

### 4. ACT (è¡ŒåŠ¨) â€” Remediation / ä¿®å¤

#### 4.1 Tier 3 Actions (US DBA + China HQ) / Tier 3 æ“ä½œ

```bash
# STEP 1: Kill all heavy operations immediately / æ­¥éª¤1ï¼šç«‹å³ç»ˆæ­¢æ‰€æœ‰é‡å‹æ“ä½œ
db.currentOp({"secs_running": {"$gt": 3}}).inprog.forEach(function(op) {
  db.killOp(op.opid);
  print("EMERGENCY KILL: " + op.opid);
});

# STEP 2: Scale up instance class (requires China HQ approval)
# æ­¥éª¤2ï¼šå‡çº§å®ä¾‹è§„æ ¼ï¼ˆéœ€è¦ä¸­å›½æ€»éƒ¨æ‰¹å‡†ï¼‰
aws docdb modify-db-instance \
  --db-instance-identifier INSTANCE_NAME \
  --db-instance-class db.r6g.xlarge \
  --apply-immediately --region us-east-1
# WARNING: Instance reboots during class change! Expect ~5min downtime.
# è­¦å‘Šï¼šæ›´æ”¹è§„æ ¼æœŸé—´å®ä¾‹é‡å¯ï¼é¢„è®¡çº¦5åˆ†é’Ÿåœæœºã€‚

# STEP 3: If instance cannot be scaled, failover to a larger replica
# æ­¥éª¤3ï¼šå¦‚æœæ— æ³•å‡çº§å®ä¾‹ï¼Œæ•…éšœè½¬ç§»åˆ°æ›´å¤§çš„å‰¯æœ¬
aws docdb failover-db-cluster \
  --db-cluster-identifier CLUSTER_NAME \
  --region us-east-1
```

#### 4.2 Escalation Criteria / å‡çº§æ ‡å‡†

| Condition / æ¡ä»¶ | Action / æ“ä½œ |
|-----------|--------|
| Memory still < 200MB after killing ops / ç»ˆæ­¢æ“ä½œåå†…å­˜ä» < 200MB | Scale up instance immediately / ç«‹å³å‡çº§å®ä¾‹ |
| Instance crash or OOM / å®ä¾‹å´©æºƒæˆ– OOM | Failover + AWS Support case / æ•…éšœè½¬ç§» + æäº¤ AWS æ”¯æŒå·¥å• |
| Golden path impacted > 5 min / é»„é‡‘æµç¨‹å—å½±å“ > 5åˆ†é’Ÿ | All hands + China HQ CTO / å…¨å‘˜ + ä¸­å›½æ€»éƒ¨ CTO |

---

### 5. AFTERMATH (å–„å) â€” Post-Incident / äº‹åå¤„ç†

#### 5.1 Prevention / é¢„é˜²

```
[ ] Mandatory incident report within 24 hours / 24å°æ—¶å†…å¿…é¡»æäº¤äº‹ä»¶æŠ¥å‘Š
[ ] Instance class review â€” permanently upgrade if needed / å®ä¾‹è§„æ ¼å®¡æŸ¥ â€” å¿…è¦æ—¶æ°¸ä¹…å‡çº§
[ ] Application memory profiling / åº”ç”¨å†…å­˜åˆ†æ
[ ] Set up memory trending alerts at 70% / è®¾ç½® 70% å†…å­˜è¶‹åŠ¿å‘Šè­¦
[ ] Connection pool audit across all services / æ‰€æœ‰æœåŠ¡çš„è¿æ¥æ± å®¡è®¡
[ ] Evaluate adding read replicas / è¯„ä¼°æ·»åŠ åªè¯»å‰¯æœ¬
```

#### 5.2 Related Alerts / ç›¸å…³å‘Šè­¦

| Alert ID | Name | Relationship / å…³ç³» |
|----------|------|-------------|
| LCK-MG-003 | MongoMemoryLow_Warning | Warning precursor / é¢„è­¦å‰å…† |
| LCK-MG-001 | MongoCpuHigh_Warning | Low memory causes CPU spikes (swapping) / ä½å†…å­˜å¯¼è‡´ CPU å³°å€¼ |
| LCK-MG-002 | MongoCpuHigh_Critical | May fire simultaneously / å¯èƒ½åŒæ—¶è§¦å‘ |
| LCK-MG-005 | MongoConnectionHigh_Warning | Connections consume memory / è¿æ¥æ¶ˆè€—å†…å­˜ |

---

## LCK-MG-005 â€” MongoConnectionHigh_Warning

### Metadata / å…ƒæ•°æ®

```yaml
alert_id: "LCK-MG-005"
alert_name: "MongoConnectionHigh_Warning"
severity: "warning"
tier: "2"
category: "db-mongo"
team: "dba"
first_responder: "US DBA"
old_ids_replaced: "â€”"
migration_action: "NEW"
sla_response: "Tier 2: 15min acknowledge, 1h first update, 4h resolution"
skill_reference: "/app/skills/apm-alert-investigation.md"
last_updated: "2026-02-16"
```

### Alert Rule (from alert-rules-complete.yml) / å‘Šè­¦è§„åˆ™

```yaml
- alert: MongoConnectionHighWarning
  expr: |
    mongodb_connections_current{env="production"}
    / mongodb_connections_max{env="production"} * 100 > 80
  for: 5m
  labels:
    severity: "warning"
    tier: "2"
    team: "dba"
    category: "db-mongo"
    service: "documentdb-mongo"
  annotations:
    summary: "[LCK-NA-DB-MONGO] ConnectionHigh_Warning - {{ $labels.instance }}"
    impact: "MongoDB connection pool nearing capacity; new connections may be refused."
    notification_channel: "wecom+twilio-lead"
```

### 1. ASSESS (è¯„ä¼°) â€” First 2 Minutes / å‰2åˆ†é’Ÿ

**Goal / ç›®æ ‡:** Determine connection consumption source and assess risk of connection exhaustion.
ç¡®å®šè¿æ¥æ¶ˆè€—æ¥æºå¹¶è¯„ä¼°è¿æ¥è€—å°½é£é™©ã€‚

#### 1.1 Golden Path Impact Check / é»„é‡‘æµç¨‹å½±å“æ£€æŸ¥

```bash
# Check order flow / æ£€æŸ¥è®¢å•æµ
curl -s "http://prometheus:9090/api/v1/query?query=sum_over_time(business_completed_orders_total[10m])"

# Check connection utilization / æ£€æŸ¥è¿æ¥åˆ©ç”¨ç‡
curl -s "http://prometheus:9090/api/v1/query?query=mongodb_connections_current{env='production'}/mongodb_connections_max{env='production'}*100" | jq '.data.result[] | {instance: .metric.instance, connection_pct: .value[1]}'
```

#### 1.2 Quick Triage / å¿«é€Ÿåˆ†ç±»

```bash
# Current and max connections / å½“å‰å’Œæœ€å¤§è¿æ¥æ•°
curl -s "http://prometheus:9090/api/v1/query?query=mongodb_connections_current{env='production'}" | jq '.data.result[] | {instance: .metric.instance, current: .value[1]}'
curl -s "http://prometheus:9090/api/v1/query?query=mongodb_connections_max{env='production'}" | jq '.data.result[] | {instance: .metric.instance, max: .value[1]}'

# Check if recent deployments may have caused connection surge / æ£€æŸ¥æœ€è¿‘éƒ¨ç½²æ˜¯å¦å¯¼è‡´è¿æ¥æ¿€å¢
kubectl get events -n production --sort-by='.lastTimestamp' --field-selector reason=Pulling | tail -10
```

#### 1.3 Severity Classification / ä¸¥é‡ç¨‹åº¦åˆ†ç±»

| Condition / æ¡ä»¶ | Severity / ä¸¥é‡ç¨‹åº¦ | Action / æ“ä½œ |
|-----------|----------|--------|
| > 80% connections, new connections failing / > 80% è¿æ¥ï¼Œæ–°è¿æ¥å¤±è´¥ | **Warning -> Tier 2** (may escalate) | Immediate investigation / ç«‹å³è°ƒæŸ¥ |
| > 80% connections, apps functioning / > 80% è¿æ¥ï¼Œåº”ç”¨æ­£å¸¸ | **Warning -> Tier 2** | Investigate connection pool / è°ƒæŸ¥è¿æ¥æ±  |
| Connection count decreasing / è¿æ¥æ•°ä¸‹é™ | **Resolving** | Monitor trend / ç›‘æ§è¶‹åŠ¿ |

---

### 2. ACKNOWLEDGE (ç¡®è®¤) â€” Within 15 Minutes / 15åˆ†é’Ÿå†…

#### 2.1 Silence Alert / é™é»˜å‘Šè­¦

```bash
amtool silence add \
  alertname="MongoConnectionHighWarning" \
  category="db-mongo" \
  --duration="30m" \
  --comment="Investigating high connections - YOUR_NAME" \
  --author="YOUR_NAME"
```

#### 2.2 WeCom Notification / ä¼ä¸šå¾®ä¿¡é€šçŸ¥

```
ğŸ”” Alert Acknowledged / å‘Šè­¦å·²ç¡®è®¤
Alert: MongoConnectionHigh_Warning (LCK-MG-005)
Severity: Warning | Tier: 2
Owner: {your_name}
Status: Investigating / è°ƒæŸ¥ä¸­
Instance: {instance}
Connection Usage: {value}% of max
ETA for update: {time + 15min}
```

#### 2.3 SLA Timers / SLA æ—¶é—´è¦æ±‚

| Milestone / é‡Œç¨‹ç¢‘ | Deadline / æˆªæ­¢æ—¶é—´ |
|-----------|----------|
| Acknowledge / ç¡®è®¤ | 15 min |
| First Update / é¦–æ¬¡æ›´æ–° | 1 hour |
| Resolution / è§£å†³ | 4 hours |

---

### 3. ANALYZE (åˆ†æ) â€” Root Cause Investigation / æ ¹å› è°ƒæŸ¥

#### 3.1 Common Causes Checklist / å¸¸è§åŸå› æ¸…å•

```
[ ] Application pod scaling event (more pods = more connections) / åº”ç”¨ Pod æ‰©å±•äº‹ä»¶
[ ] Connection pool misconfiguration (maxPoolSize too high) / è¿æ¥æ± é…ç½®é”™è¯¯
[ ] Connection leak (connections not properly closed) / è¿æ¥æ³„æ¼ï¼ˆè¿æ¥æœªæ­£ç¡®å…³é—­ï¼‰
[ ] Application restart causing reconnection storm / åº”ç”¨é‡å¯å¯¼è‡´é‡è¿é£æš´
[ ] Slow queries holding connections open / æ…¢æŸ¥è¯¢å ç”¨è¿æ¥
[ ] Cron job or batch process opening many connections / å®šæ—¶ä»»åŠ¡æˆ–æ‰¹å¤„ç†æ‰“å¼€å¤§é‡è¿æ¥
```

#### 3.2 Diagnostic Commands / è¯Šæ–­å‘½ä»¤

```bash
# Connect to DocumentDB / è¿æ¥ DocumentDB
mongo --tls --host CLUSTER_ENDPOINT:27017 \
  --tlsCAFile global-bundle.pem \
  --username dbadmin --password PASSWORD

# Connection details / è¿æ¥è¯¦æƒ…
db.serverStatus().connections
# Output: { "current": N, "available": M, "totalCreated": T }

# What's each connection doing? / æ¯ä¸ªè¿æ¥åœ¨åšä»€ä¹ˆï¼Ÿ
db.currentOp(true).inprog.forEach(function(op) {
  print("client: " + op.client + " | ns: " + op.ns + " | secs: " + (op.secs_running || 0) + " | op: " + op.op);
});

# Count connections by client IP (identify top consumers) / æŒ‰å®¢æˆ·ç«¯ IP ç»Ÿè®¡è¿æ¥æ•°
db.currentOp(true).inprog.reduce(function(acc, op) {
  var ip = (op.client || "unknown").split(":")[0];
  acc[ip] = (acc[ip] || 0) + 1;
  return acc;
}, {})

# Check if connections are idle / æ£€æŸ¥è¿æ¥æ˜¯å¦ç©ºé—²
db.currentOp(true).inprog.filter(function(op) { return op.op === "none"; }).length
```

```bash
# AWS CLI: Connection history / AWS CLI: è¿æ¥å†å²
aws cloudwatch get-metric-statistics \
  --namespace AWS/DocDB \
  --metric-name DatabaseConnections \
  --dimensions Name=DBInstanceIdentifier,Value=INSTANCE_NAME \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \
  --period 60 --statistics Maximum --region us-east-1

# Check pod count (correlation with connections) / æ£€æŸ¥ Pod æ•°é‡ï¼ˆä¸è¿æ¥æ•°çš„ç›¸å…³æ€§ï¼‰
kubectl get pods -n production --no-headers | wc -l

# Recent HPA scaling events / æœ€è¿‘çš„ HPA æ‰©å±•äº‹ä»¶
kubectl get events -n production --field-selector reason=SuccessfulRescale --sort-by='.lastTimestamp' | tail -10
```

#### 3.3 Root Cause Decision Tree / æ ¹å› å†³ç­–æ ‘

```
Connections > 80% of max?
â”œâ”€ Yes â†’ Check connection growth rate / æ£€æŸ¥è¿æ¥å¢é•¿é€Ÿç‡
â”‚  â”œâ”€ Sudden spike / çªç„¶é£™å‡ â†’ Check for app restart or scaling event / æ£€æŸ¥åº”ç”¨é‡å¯æˆ–æ‰©å±•äº‹ä»¶
â”‚  â”‚  â”œâ”€ App scaling event â†’ Expected, wait for stabilization / é¢„æœŸå†…ï¼Œç­‰å¾…ç¨³å®š
â”‚  â”‚  â””â”€ No scaling event â†’ Connection leak suspected / æ€€ç–‘è¿æ¥æ³„æ¼
â”‚  â””â”€ Gradual increase / é€æ¸å¢åŠ  â†’ Check idle connection count / æ£€æŸ¥ç©ºé—²è¿æ¥æ•°
â”‚     â”œâ”€ Many idle connections â†’ Connection pool not recycling / è¿æ¥æ± æœªå›æ”¶
â”‚     â””â”€ Active connections â†’ Workload increase / å·¥ä½œè´Ÿè½½å¢åŠ 
â””â”€ No â†’ Alert resolving / å‘Šè­¦æ¢å¤ä¸­
```

---

### 4. ACT (è¡ŒåŠ¨) â€” Remediation / ä¿®å¤

#### 4.1 Tier 2 Actions (US DBA Authority) / Tier 2 æ“ä½œ

```bash
# Kill idle connections (holding resources but not working)
# ç»ˆæ­¢ç©ºé—²è¿æ¥ï¼ˆå ç”¨èµ„æºä½†æœªå·¥ä½œï¼‰
# In DocumentDB, idle connections are managed by the application pool.
# Coordinate with application teams to:
# ä¸åº”ç”¨å›¢é˜Ÿåè°ƒ:

# 1. Reduce maxPoolSize in application connection strings
# 1. å‡å°‘åº”ç”¨è¿æ¥å­—ç¬¦ä¸²ä¸­çš„ maxPoolSize
# Example (Java/Node.js): maxPoolSize=20 â†’ maxPoolSize=10

# 2. Enable maxIdleTimeMS to close idle connections
# 2. å¯ç”¨ maxIdleTimeMS å…³é—­ç©ºé—²è¿æ¥
# Example: mongodb://...?maxIdleTimeMS=60000

# Kill long-running operations that are holding connections / ç»ˆæ­¢é•¿æ—¶é—´è¿è¡Œçš„æ“ä½œ
db.currentOp({"secs_running": {"$gt": 60}}).inprog.forEach(function(op) {
  db.killOp(op.opid);
  print("Killed idle/long op: " + op.opid);
});
```

#### 4.2 Escalation Criteria / å‡çº§æ ‡å‡†

| Condition / æ¡ä»¶ | Action / æ“ä½œ |
|-----------|--------|
| Connections reach 95% of max / è¿æ¥è¾¾åˆ°æœ€å¤§å€¼çš„ 95% | Escalate to Tier 3 / å‡çº§åˆ° Tier 3 |
| New connections being refused (app errors) / æ–°è¿æ¥è¢«æ‹’ç»ï¼ˆåº”ç”¨æŠ¥é”™ï¼‰ | Escalate to Tier 3 / å‡çº§åˆ° Tier 3 |
| Cannot identify connection source in 30 min / 30åˆ†é’Ÿå†…æ— æ³•ç¡®å®šè¿æ¥æ¥æº | Escalate to Tier 3 / å‡çº§åˆ° Tier 3 |

```bash
# If Tier 3 escalation needed: Scale up instance (more memory = more max connections)
# å¦‚æœéœ€è¦å‡çº§åˆ° Tier 3ï¼šå‡çº§å®ä¾‹ï¼ˆæ›´å¤šå†…å­˜ = æ›´å¤šæœ€å¤§è¿æ¥æ•°ï¼‰
# DocumentDB max connections â‰ˆ 100 per GiB RAM
aws docdb modify-db-instance \
  --db-instance-identifier INSTANCE_NAME \
  --db-instance-class db.r6g.xlarge \
  --apply-immediately --region us-east-1
```

---

### 5. AFTERMATH (å–„å) â€” Post-Incident / äº‹åå¤„ç†

#### 5.1 Prevention / é¢„é˜²

```
[ ] Audit all application connection pool configurations / å®¡è®¡æ‰€æœ‰åº”ç”¨è¿æ¥æ± é…ç½®
[ ] Set maxPoolSize appropriate for workload / è®¾ç½®é€‚åˆå·¥ä½œè´Ÿè½½çš„ maxPoolSize
[ ] Enable maxIdleTimeMS on all connection strings / åœ¨æ‰€æœ‰è¿æ¥å­—ç¬¦ä¸²ä¸Šå¯ç”¨ maxIdleTimeMS
[ ] Add connection monitoring to application health checks / å°†è¿æ¥ç›‘æ§æ·»åŠ åˆ°åº”ç”¨å¥åº·æ£€æŸ¥
[ ] Document expected connection count per service / è®°å½•æ¯ä¸ªæœåŠ¡çš„é¢„æœŸè¿æ¥æ•°
[ ] Consider connection pooling middleware if many microservices / å¦‚æœæœ‰å¾ˆå¤šå¾®æœåŠ¡è€ƒè™‘è¿æ¥æ± ä¸­é—´ä»¶
```

#### 5.2 Related Alerts / ç›¸å…³å‘Šè­¦

| Alert ID | Name | Relationship / å…³ç³» |
|----------|------|-------------|
| LCK-MG-001 | MongoCpuHigh_Warning | High connections increase CPU / é«˜è¿æ¥æ•°å¢åŠ  CPU |
| LCK-MG-003 | MongoMemoryLow_Warning | Each connection uses memory / æ¯ä¸ªè¿æ¥å ç”¨å†…å­˜ |
| LCK-MG-004 | MongoMemoryLow_Critical | Connection exhaustion may trigger OOM / è¿æ¥è€—å°½å¯èƒ½è§¦å‘ OOM |

#### 5.3 Knowledge Base Update / çŸ¥è¯†åº“æ›´æ–°

After resolution, update / è§£å†³åæ›´æ–°:
1. This runbook â€” add connection source patterns / æ·»åŠ è¿æ¥æ¥æºæ¨¡å¼
2. Application docs â€” update recommended pool settings / æ›´æ–°æ¨èçš„è¿æ¥æ± è®¾ç½®
3. Alert thresholds â€” PR to `alert-rules-complete.yml` if needed / å¦‚éœ€è°ƒæ•´æäº¤ PR
4. Monitoring â€” add per-service connection tracking dashboard / æ·»åŠ æŒ‰æœåŠ¡çš„è¿æ¥è·Ÿè¸ªä»ªè¡¨æ¿

---

## Appendix A: DocumentDB Instance Reference / é™„å½•Aï¼šDocumentDB å®ä¾‹å‚è€ƒ

| Instance Class / å®ä¾‹è§„æ ¼ | vCPU | Memory (GiB) | Max Connections (est.) / æœ€å¤§è¿æ¥æ•°ï¼ˆä¼°è®¡ï¼‰ |
|--------------|------|-------------|--------------------------|
| db.r6g.large | 2 | 16 | ~1,600 |
| db.r6g.xlarge | 4 | 32 | ~3,200 |
| db.r6g.2xlarge | 8 | 64 | ~6,400 |
| db.r6g.4xlarge | 16 | 128 | ~12,800 |
| db.t3.medium | 2 | 4 | ~400 |

> Max connections formula / æœ€å¤§è¿æ¥æ•°å…¬å¼: ~100 connections per GiB of RAM

---

## Appendix B: Old-to-New Alert ID Mapping / é™„å½•Bï¼šæ–°æ—§å‘Šè­¦IDå¯¹ç…§

| Old ID / æ—§ID | Old Name / æ—§åç§° | New ID / æ–°ID | New Name / æ–°åç§° | Action / æ“ä½œ |
|--------|----------|--------|----------|--------|
| ALR-030 | MongoCpuHigh | LCK-MG-001 | MongoCpuHigh_Warning | KEEP â€” split warning tier |
| ALR-030, ALR-031 | MongoCpuHigh, MongoCpuCritical | LCK-MG-002 | MongoCpuHigh_Critical | MERGE â€” unified critical |
| ALR-032 | MongoMemoryLow | LCK-MG-003 | MongoMemoryLow_Warning | KEEP â€” warning tier |
| ALR-032 | MongoMemoryLow | LCK-MG-004 | MongoMemoryLow_Critical | SPLIT â€” new critical tier |
| â€” | (none) | LCK-MG-005 | MongoConnectionHigh_Warning | NEW â€” no prior coverage |

---

## Appendix C: MCP Skill & Datasource Quick Reference / é™„å½•Cï¼šMCP æŠ€èƒ½å’Œæ•°æ®æºå¿«é€Ÿå‚è€ƒ

### Skill Files / æŠ€èƒ½æ–‡ä»¶

| Category / åˆ†ç±» | Skill File / æŠ€èƒ½æ–‡ä»¶ | Invocation / è°ƒç”¨ |
|----------|-----------|------------|
| APM/General | `/app/skills/apm-alert-investigation.md` | `/investigate-apm` |
| RDS (related) | `/app/skills/rds-alert-investigation.md` | `/investigate-rds` |
| EC2 (if host issue) | `/app/skills/ec2-alert-investigation.md` | `/investigate-ec2` |

### Datasource UIDs / æ•°æ®æºUID

| Datasource | UID | Purpose / ç”¨é€” |
|------------|-----|---------|
| UMBQuerier-Luckin | `df8o21agxtkw0d` | Primary Prometheus (MongoDB, node, RDS, business metrics) |
| prometheus | `ff7hkeec6c9a8e` | General metrics / é€šç”¨æŒ‡æ ‡ |
| prometheus_redis | `ff6p0gjt24phce` | Redis/ElastiCache metrics / Redis æŒ‡æ ‡ |

### VMAlert Endpoints / VMAlert èŠ‚ç‚¹

| Instance / å®ä¾‹ | IP:Port | Role / è§’è‰² |
|----------|---------|------|
| Basic | 10.238.3.153:8880 | Infrastructure alert evaluation (includes MongoDB) |
| APM-1 | 10.238.3.137:8880 | APM alert evaluation |
| APM-2 | 10.238.3.143:8880 | APM alert evaluation |
| APM-3 | 10.238.3.52:8880 | APM alert evaluation |

### Dashboard URLs / ä»ªè¡¨æ¿é“¾æ¥

```
MongoDB Overview: https://grafana.luckinus.com/d/mongo-overview
MongoDB Memory:   https://grafana.luckinus.com/d/mongo-memory
MongoDB Connections: https://grafana.luckinus.com/d/mongo-connections
```

---

*End of Part 5 â€” DB-MONGO Runbooks*
*ç¬¬5éƒ¨åˆ†ç»“æŸ â€” DB-MONGO è¿ç»´æ‰‹å†Œ*
